{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec67850",
   "metadata": {},
   "source": [
    "## TITLE: Random Locs Same Params\n",
    "\n",
    "**Purpose:** \n",
    "\n",
    "**Dependencies:** \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f91aef-bb8e-4f86-9def-146ae0c0702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from clawpack.geoclaw import topotools\n",
    "sys.path.insert(0, '/home/catherinej/BarrierBreach/src/')\n",
    "import breach_randomization as br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f539aed-173c-4b14-a8d3-1024dbb041ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import bathymetry_adulterant from claw_code\n",
    "sys.path.insert(0, '/home/catherinej/claw_code/src/claw_code/post')\n",
    "import waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c281bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomBreach(): \n",
    "    def __init__(self, breach_data_path, gauge_location_path, gauge_data_path, topo_path, masked_path): \n",
    "        self.breach_data_path = breach_data_path\n",
    "        self.gauge_location_path = gauge_location_path\n",
    "        self.gauge_data_path = gauge_data_path\n",
    "        self.topo_path = topo_path\n",
    "        self.topo_data = br.load_topography(self.topo_path)\n",
    "        self.masked_island = masked_path\n",
    "        self.gauge_names = self.load_gauge_names()\n",
    "        self.gauge_data = br.load_gauge_data(self.gauge_names.index.values, self.gauge_data_path)\n",
    "        self.breach_data = self.load_existing_breach()    \n",
    "    \n",
    "        \n",
    "    def load_gauge_names(self):\n",
    "        df = pd.read_csv(self.gauge_location_path)\n",
    "        df = df.drop(['Unnamed: 0', 'dist'], axis=1)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def load_existing_breach(self):\n",
    "        breach_data_files = glob.glob(os.path.join(self.breach_data_path, '**', 'breach.data'), recursive=True)\n",
    "        data_files = [d for d in breach_data_files if not d.split('/')[-2] == '_output']\n",
    "        breach_data = {}\n",
    "        for file in data_files:\n",
    "            directory = file.split('/')[-2]\n",
    "            if directory not in ['no_breach', '15m']:\n",
    "                with open(file) as f:\n",
    "                    data = f.read()\n",
    "                data = data.split('\\n')\n",
    "                data = [line.split(' ') for line in data]\n",
    "                data.pop(0)\n",
    "                names = data.pop(0)\n",
    "                names.append('Depth')\n",
    "                d = {k: v for k,v in zip(names, data) if k != 'sigma,'}\n",
    "                df = pd.DataFrame(d)\n",
    "                df.columns = [col.replace(',', '') for col in df.columns]\n",
    "                df = df.apply(pd.to_numeric, errors='ignore')\n",
    "                df.columns = [x.title() for x in df.columns]\n",
    "                dist = [abs(west - east) for west, east\n",
    "                        in zip(df['West'], df['East'])]\n",
    "                df['Distance'] = dist\n",
    "                breach_data[directory] = df\n",
    "        return breach_data\n",
    "        \n",
    "        \n",
    "    def check_location_viability(self, max_dune, gauge_no):\n",
    "        \"\"\"Checks to make sure that a breach location reaches the required minimum % of dune height\n",
    "\n",
    "        Args:\n",
    "            df (_dataframe_): data frame of all tide gauge timeseries\n",
    "            max_dune (_type_): max dune height at chosen breach location\n",
    "        \"\"\"\n",
    "        breach_time = []\n",
    "        x_percent = max_dune * .20\n",
    "        # Convert the array elements to strings and create a list of column names\n",
    "        column_names_to_keep = [f\"{num}_eta\" for num in gauge_no]\n",
    "\n",
    "        # Use the filter function to select columns based on the list of column names\n",
    "        gauge = self.gauge_data.filter(items=column_names_to_keep, axis=1)\n",
    "\n",
    "        # gauge = self.gauge_data[gauge_no]\n",
    "        cols_greater = (gauge >= x_percent).any()\n",
    "        if cols_greater.any():\n",
    "            time_to_exceed_x_percent = [br.first_greater(gauge, x_percent, col) for col in cols_greater.index]\n",
    "            breach_start = min([x for x in time_to_exceed_x_percent if type(x) == np.float64])\n",
    "            if breach_start == 27000.0:\n",
    "                print('these columns suck:', cols_greater, 'dune height is: ', x_percent)\n",
    "            breach_stop = breach_start + 7200.0\n",
    "            return breach_start, breach_stop\n",
    "        else:\n",
    "            print('This location is not viable')\n",
    "            return False, False\n",
    "            # WRite location to file and break to restart randomize location?\n",
    "        \n",
    "        \n",
    "    def randomize_location(self):\n",
    "        \"\"\"Takes a collection of breach data and randomizes the locations\n",
    "\n",
    "        Args:\n",
    "            df (pandas dataframe): breach data, location, width, depth, timing\n",
    "        \"\"\"\n",
    "        bad_breach = []\n",
    "        breach_loc = br.get_random_location(self.masked_island)\n",
    "        lat = (breach_loc['south'][1] + breach_loc['north'][1])/2\n",
    "        \n",
    "        max_dune = br.max_dune_height(self.topo_data, breach_loc['south'][0], breach_loc['north'][0],\n",
    "                                    breach_loc['lon'][0])\n",
    "        if max_dune == 0.0:\n",
    "            print('Why is the dune at 0.0?,', breach_loc)\n",
    "\n",
    "        tide_gauges = br.find_nearest_gauges(self.gauge_names, breach_loc['lon'][1], lat,  1000)\n",
    "        \n",
    "        \n",
    "        breach_start, breach_stop = self.check_location_viability(max_dune)\n",
    "        if breach_start:\n",
    "            # print(breach_start, 'something isnt false')\n",
    "            new_breach_data = {'south' : breach_loc['south'][1],\n",
    "                            'north': breach_loc['north'][1],\n",
    "                            'mu': breach_loc['lon'][1],\n",
    "                            'start': breach_start,\n",
    "                            'stop': breach_stop,\n",
    "                            'bad_breach': bad_breach\n",
    "                            }\n",
    "            # print(new_breach_data)\n",
    "            return new_breach_data\n",
    "            # do more stuff\n",
    "        else:\n",
    "            bad_breach.append(breach_loc)\n",
    "            return self.randomize_location()\n",
    "        \n",
    "    \n",
    "    def arrange_data(self, new_breach, key):\n",
    "        south = [x['south'] for x in new_breach]\n",
    "        north = [x['north'] for x in new_breach]\n",
    "        mu = [x['mu'] for x in new_breach]\n",
    "        start = [x['start'] for x in new_breach]\n",
    "        stop = [x['stop'] for x in new_breach]\n",
    "        west = [x['mu'] - y/2 for x, y in zip(new_breach, randb.breach_data[key]['Distance'])]\n",
    "        east = [x['mu'] + y/2 for x, y in zip(new_breach, randb.breach_data[key]['Distance'])]\n",
    "        data = {'South': south,\n",
    "                'North': north,\n",
    "                'Mu': mu,\n",
    "                'Start_Time': start,\n",
    "                'End_Time': stop,\n",
    "                'West': west,\n",
    "                'East': east}\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def combine_data(self, key, data):\n",
    "        df = pd.DataFrame(data)\n",
    "        self.breach_data[key] = self.breach_data[key].drop(columns=list(data.keys()))\n",
    "        self.breach_data[key] = pd.concat([self.breach_data[key], df], axis=1)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def write_breach_data(self, num_breaches, write_path, key):\n",
    "        comment_str = 'breach_trigger, south, north, west, east, mu, sigma, time_factor, start_time, end_time depth'\n",
    "        write_order = ['Breach_Trigger', 'South', \"North\", 'West', 'East',\n",
    "                       'Mu', 'Sigma', 'Time_Factor', 'Start_Time', 'End_TIme', \n",
    "                       'Depth']\n",
    "        with open(os.path.join(write_path, 'breach.data'), 'w') as f:\n",
    "            f.write(f'{num_breaches}' + '\\n')\n",
    "            f.write(comment_str + '\\n')\n",
    "            for param in write_order:\n",
    "                if param == 'Sigma':\n",
    "                    f.write(f'1' + '\\n')\n",
    "                else:\n",
    "                    f.write(' '.join(map(str, self.breach_data[key][param])) + '\\n')\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "417dc276-9bdc-4841-a84b-0397c7ba25e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "randb = RandomBreach('/home/catherinej/300km_breach/no_breach_300km',\n",
    "                 '/home/catherinej/BarrierBreach/data/ocean_gauges.csv',\n",
    "                 '/home/catherinej/300km_breach/no_breach_300km/_output',\n",
    "                 '/home/catherinej/bathymetry/moriches.nc',\n",
    "                 '/home/catherinej/BarrierBreach/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61616a2-3f3e-495c-b61a-4e4c2ad45e36",
   "metadata": {},
   "source": [
    "filename = 'breach.data'\n",
    "PATH = '/home/catherinej/width_depth/'\n",
    "breach_data_files = glob.glob(os.path.join(PATH, '**', filename), recursive=True)\n",
    "data_files = [d for d in breach_data_files if not d.split('/')[-2] == '_output']\n",
    "\n",
    "for file in data_files:\n",
    "    directory = file.split('/')[-2]\n",
    "    if directory not in ['no_breach', '15m']:\n",
    "        old_breach_params = load_existing_breach(file)\n",
    "        breach_loc = [randomize_location() for row in zip(old_breach_params['Breach_Trigger'], old_breach_params['Distance'] )]\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e7cc00a1-f159-45dc-98f6-815194210fee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "breach = randb.breach_data['no_breach_300km']\n",
    "breach['s'] = [br.find_nearest_bathy_val(randb.topo_data, s, mu)[1] for s, mu in zip(breach['South'],  breach['Mu'])]\n",
    "breach['n'] = [br.find_nearest_bathy_val(randb.topo_data, n, mu)[1] for n, mu in zip(breach['North'], breach['Mu'])]\n",
    "breach['lon'] = [br.find_nearest_bathy_val(randb.topo_data, n, mu)[0] for n, mu in zip(breach['North'], breach['Mu'])]\n",
    "breach['max_dune'] = [br.max_dune_height(randb.topo_data, s, n, mu) for s, n, mu in zip(breach['s'], breach['n'], breach['lon'])]\n",
    "breach\n",
    "                    \n",
    "#     lat = (row['south'] + row['north'])/2\n",
    "\n",
    "#     max_dune = br.max_dune_height(self.topo_data, row['south'], row['north'],\n",
    "#                                 row['mu'])\n",
    "#     if max_dune == 0.0:\n",
    "#         print('Why is the dune at 0.0?,', breach_loc)\n",
    "\n",
    "breach['tide_gauges'] = [br.find_nearest_gauges(randb.gauge_names, mu, (s+n)/2,  1000).index for mu, s, n in zip(breach['Mu'], breach['South'], breach['North'])]\n",
    "\n",
    "\n",
    "breach['breach_timing'] = [randb.check_location_viability(max_dune, gauges.values) for max_dune, gauges in zip(breach['max_dune'], breach['tide_gauges'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "172e2a3f-64db-4247-99d9-ccebb54ffdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "breach[['Start_Time', 'End_Time']].to_pickle('6_breach_times.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b22a4361-d4ac-4e0e-8b37-23455b0a96da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214219.9</td>\n",
       "      <td>221419.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213647.4</td>\n",
       "      <td>220847.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>214603.3</td>\n",
       "      <td>221803.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>214556.6</td>\n",
       "      <td>221756.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>216243.2</td>\n",
       "      <td>223443.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>215135.5</td>\n",
       "      <td>222335.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start_Time  End_Time\n",
       "0    214219.9  221419.9\n",
       "1    213647.4  220847.4\n",
       "2    214603.3  221803.3\n",
       "3    214556.6  221756.6\n",
       "4    216243.2  223443.2\n",
       "5    215135.5  222335.5"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = pd.read_pickle('6_breach_times.pkl')\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a4720-e12c-46dc-ac3a-970da3c76f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a1513-39fc-4fa9-a614-01f0acfb05fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a71b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_loca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eab116a8-67c2-4dde-88e5-fcbcb67dc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fldr_label = re.split(r'(\\d+)', key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9028b4a2-9ed7-43d1-b79e-d47a4fcccadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d_rand_16'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{fldr_label[0]}_rand_{fldr_label[1]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe53013f-483e-4a1a-877e-5ac7493d67a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-72.64312666295108 -72.65393242221057 -72.81251799628774 -72.77394255184257 -72.71010210739686 -72.76479301480535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(map(str, randb.breach_data[key]['West'])) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74adb75b-6fd6-4645-9ffc-9ca63636233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runit(write_path):\n",
    "    num_breaches = 6\n",
    "    randb = RandomBreach('/home/catherinej/width_depth',\n",
    "                         '/home/catherinej/BarrierBreach/data/ocean_gauges.csv',\n",
    "                         '/home/catherinej/width_depth/no_breach/_output',\n",
    "                         '/home/catherinej/bathymetry/moriches.nc',\n",
    "                         '/home/catherinej/BarrierBreach/data/')\n",
    "    for key in randb.breach_data:\n",
    "        breach = randb.breach_data[key]\n",
    "        new_breach = [randb.randomize_location() for row in breach.Breach_Trigger]\n",
    "        data = randb.arrange_data(new_breach, key)\n",
    "        randb.combine_data(key, data)\n",
    "        randb.write_breach_data(num_breaches, write_path, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64262c06-81c3-43c9-8a0b-22f8b9fe8a27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m randb\u001b[38;5;241m.\u001b[39mbreach_data[\u001b[43mkey\u001b[49m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'key' is not defined"
     ]
    }
   ],
   "source": [
    "randb.breach_data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c51669d4-0503-44a1-a7a7-6adf855e3df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['load_all_waveforms.py',\n",
       " '.ipynb_checkpoints',\n",
       " 'random_locs.py',\n",
       " '__init__.py',\n",
       " 'random_locs_same_params.ipynb']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f4d8aa1-f69c-4bd7-bd38-0fe38701782b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/catherinej/BarrierBreach/src/tools/load_all_waveforms.py\n",
      "/home/catherinej/BarrierBreach/src/tools/.ipynb_checkpoints\n",
      "/home/catherinej/BarrierBreach/src/tools/random_locs.py\n",
      "/home/catherinej/BarrierBreach/src/tools/__init__.py\n",
      "/home/catherinej/BarrierBreach/src/tools/random_locs_same_params.ipynb\n"
     ]
    }
   ],
   "source": [
    "source_dir = os.getcwd()\n",
    "for file in os.listdir(source_dir):\n",
    "    print(os.path.join(source_dir , file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940d26c-05b9-4c2a-ba56-c684aa9e4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(source_folder):\n",
    "    # construct full file path\n",
    "    source = source_folder + file_name\n",
    "    destination = destination_folder + file_name\n",
    "    # copy only files\n",
    "    if os.path.isfile(source):\n",
    "        shutil.copy(source, destination)\n",
    "        print('copied', file_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "55340439c73830d36d17cf7eddcf349a315216a0c923cd30144ee1886571d011"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
